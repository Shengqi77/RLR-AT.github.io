
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Long-range Turbulence Mitigation</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://jimmycv07.github.io/DiffIR2VR_web/img/pipeline.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://shengqi77.github.io/RLRat/"/>
    <meta property="og:title" content="Long-range Turbulence Mitigation: A Large-scale Dataset and A Coarse-to-fine Framework" />
    <meta property="og:description" content=" Long-range imaging inevitably suffers from atmospheric turbulence with severe geometric distortions due to random refraction of light. The further the distance, the more severe the disturbance. Despite existing research has achieved great progress in tackling short-range turbulence, there is less attention paid to long-range turbulence with significant distortions. To address this dilemma and advance the field, we construct a large-scale real long-range atmospheric turbulence dataset (RLR-AT), including 1500 turbulence sequences spanning distances from 1 Km to 13 Km. The advantages of RLR-AT compared to existing ones: turbulence with longer-distances and higher-diversity, scenes with greater-variety and larger-scale. Moreover, most existing work adopts either registration-based or decomposition-based methods to address distortions through one-step mitigation. However, they fail to effectively handle long-range turbulence due to its significant pixel displacements. In this work, we propose a coarse-to-fine framework to handle severe distortions, which cooperates dynamic turbulence and static background priors (CDSP).  On the one hand, we discover the pixel motion statistical prior of turbulence, and propose a frequency-aware reference frame for better large-scale distortion registration, greatly reducing the burden of refinement. On the other hand, we take advantage of the static prior of background, and propose a subspace-based low-rank tensor refinement model to eliminate the misalignments inevitably left by registration  while well preserving details. The dynamic and static priors complement to each other, facilitating us to progressively mitigate long-range turbulence with severe distortions. Extensive experiments demonstrate that the proposed method outperforms SOTA methods on different datasets." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Long-range Turbulence Mitigation: A Large-scale Dataset and A Coarse-to-fine Framework" />
    <meta name="twitter:description" content="Long-range imaging inevitably suffers from atmospheric turbulence with severe geometric distortions due to random refraction of light. The further the distance, the more severe the disturbance. Despite existing research has achieved great progress in tackling short-range turbulence, there is less attention paid to long-range turbulence with significant distortions. To address this dilemma and advance the field, we construct a large-scale real long-range atmospheric turbulence dataset (RLR-AT), including 1500 turbulence sequences spanning distances from 1 Km to 13 Km. The advantages of RLR-AT compared to existing ones: turbulence with longer-distances and higher-diversity, scenes with greater-variety and larger-scale. Moreover, most existing work adopts either registration-based or decomposition-based methods to address distortions through one-step mitigation. However, they fail to effectively handle long-range turbulence due to its significant pixel displacements. In this work, we propose a coarse-to-fine framework to handle severe distortions, which cooperates dynamic turbulence and static background priors (CDSP).  On the one hand, we discover the pixel motion statistical prior of turbulence, and propose a frequency-aware reference frame for better large-scale distortion registration, greatly reducing the burden of refinement. On the other hand, we take advantage of the static prior of background, and propose a subspace-based low-rank tensor refinement model to eliminate the misalignments inevitably left by registration  while well preserving details. The dynamic and static priors complement to each other, facilitating us to progressively mitigate long-range turbulence with severe distortions. Extensive experiments demonstrate that the proposed method outperforms SOTA methods on different datasets.
" />
    <meta name="twitter:image" content="https://jimmycv07.github.io/DiffIR2VR_web/img/pipeline.jpg" />


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>0Ô∏è‚É£</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
	<link rel="stylesheet" href="css/fontawesome.all.min.css">
	<link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">
    
    <link rel="stylesheet" href="css/bulma-carousel.min.css">
    <link rel="stylesheet" href="css/bulma-slider.min.css">

    <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-8ZERS5BVPS"></script>
  <script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());

	gtag('config', 'G-8ZERS5BVPS');
  </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script defer src="js/fontawesome.all.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js"></script>

    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/bulma-carousel.js"></script>
    <script src="js/bulma-slider.min.js"></script>
    <script src="js/index.js"></script>
</head>

<body style="padding: 1%; width: 100%">
    <div class="container" style="max-width: 1500px; margin: auto;" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>Long-range Turbulence Mitigation</b>:<br>A Large-scale Dataset and A Coarse-to-fine Framework</br> 
                <small>
                üî• Accepted by 2024ECCV
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://shengqi77.github.io/">
                           Shengqi Xu
                        </a>
                    </li>
                    <li>
                        <a href="https://owuchangyuo.github.io/">
                            Yi Chang
                        </a>
                    </li>
                    <li>
                        <a>
                            Shuning Cao
                        </a>
                    </li>
                    <li>
                        <a>
                            Xueyao Xao
                        </a>
                    </li>
                    <li>
                        <a>
                            Luxin Yan
                        </a>
                    </li>
                    </br>School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China.
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/pdf/2407.08377">
                            <image src="img/diff_paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/shengqi77/RLR-AT">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href=""https://drive.google.com/file/d/14z0CvHcEVhkxWu5U7nq64xmB8Apqnx54/view?usp=drive_link"">
                            <image src="img/dataset_icon.png" height="60px">
                                <h4><strong>Dataset</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>

        <section class="hero is-light is-small">
            <div class="hero-body">
              <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    
                    <div class="item">
                        <div class="video-compare-container" id="car_video2Div" style="width: 100%;">
                            <video class="video" id="car_video" loop playsinline autoPlay muted src="videos/car_video.mp4" onplay="resizeAndPlay(this)" width="100%"></video>
                            <canvas height=0 class="videoMerge" id="car_videoMerge" style="width: 100%;"></canvas>
                        </div>
                    </div>

                    <div class="item item-building_video">
                        <div class="video-compare-container" id="building_videoDiv" style="width: 100%;">
                            <video class="video" id="building_video" loop playsinline autoPlay muted src="videos/building_video.mp4" onplay="resizeAndPlay(this)" width="100%"></video>
                            <canvas height=0 class="videoMerge" id="building_videoMerge" style="width: 100%;"></canvas>
                        </div>
                    </div>

                    <div class="item">
                        <div class="video-compare-container" id="text_building_videoDiv" style="width: 100%;">
                            <video class="video" id="text_building_video" loop playsinline autoPlay muted src="videos/text_building_video.mp4" onplay="resizeAndPlay(this)" width="100%"></video>
                            <canvas height=0 class="videoMerge" id="text_building_videoMerge" style="width: 100%;"></canvas>
                        </div>
                    </div>

                    <div class="item item-text_building1_video.">
                        <div class="video-compare-container" id="text_building1_videoDiv" style="width: 100%;">
                            <video class="video" id="text_building1_video" loop playsinline autoPlay muted src="videos/text_building1_video.mp4" onplay="resizeAndPlay(this)" width="100%"></video>
                            <canvas height=0 class="videoMerge" id="text_building1_videoMerge" style="width: 100%;"></canvas>
                        </div>
                    </div>


                </div>
              </div>
            </div>
        </section>

        <div class="row">
            <div class="col-md-12 text-center">
                The proposed method <b>CDSP</b> could effectively handle long-range atmospheric turbulence with severe geometric distortions.
			</div>
        </div><br>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
			             Long-range imaging inevitably suffers from atmospheric turbulence with severe geometric distortions due to random refraction of light. The further the distance, the more severe the disturbance. Despite existing research has achieved great progress in tackling short-range turbulence, there is less attention paid to long-range turbulence with significant distortions. To address this dilemma and advance the field, we construct a large-scale real long-range atmospheric turbulence dataset (RLR-AT), including 1500 turbulence sequences spanning distances from 1 Km to 13 Km. The advantages of RLR-AT compared to existing ones: turbulence with longer-distances and higher-diversity, scenes with greater-variety and larger-scale. Moreover, most existing work adopts either registration-based or decomposition-based methods to address distortions through one-step mitigation. However, they fail to effectively handle long-range turbulence due to its significant pixel displacements. In this work, we propose a coarse-to-fine framework to handle severe distortions, which cooperates dynamic turbulence and static background priors (CDSP).  On the one hand, we discover the pixel motion statistical prior of turbulence, and propose a frequency-aware reference frame for better large-scale distortion registration, greatly reducing the burden of refinement. On the other hand, we take advantage of the static prior of background, and propose a subspace-based low-rank tensor refinement model to eliminate the misalignments inevitably left by registration  while well preserving details. The dynamic and static priors complement to each other, facilitating us to progressively mitigate long-range turbulence with severe distortions. Extensive experiments demonstrate that the proposed method outperforms SOTA methods on different datasets.
                </p>
            </div>
        </div>


	

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{yeh2024diffir2vr,
    title={DiffIR2VR-Zero: Zero-Shot Video Restoration with Diffusion-based Image Restoration Models},
    author={Chang-Han Yeh and Chin-Yang Lin and Zhixiang Wang and Chi-Wei Hsiao and Ting-Hsuan Chen and Yu-Lun Liu},
    journal={arXiv},
    year={2024}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                This research was funded by the National Science and Technology Council, Taiwan, under Grants NSTC 112-2222-E-A49-004-MY2. The authors are grateful to Google, NVIDIA, and MediaTek Inc. for generous donations. Yu-Lun Liu acknowledges the Yushan Young Fellow Program by the MOE in Taiwan.
                    <br><br>
                The website template was borrowed from <a href="http://mgharbi.com/">Micha√´l Gharbi</a> and <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
	    






